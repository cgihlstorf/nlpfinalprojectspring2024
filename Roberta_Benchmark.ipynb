{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For more information about `squadv2` metrics click here https://huggingface.co/spaces/evaluate-metric/squad_v2"
      ],
      "metadata": {
        "id": "YoJQ9kYj_J9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --quiet\n",
        "!pip install evaluate --quiet"
      ],
      "metadata": {
        "id": "ufroPJc4hpsX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "from transformers import RobertaTokenizer, RobertaForQuestionAnswering\n",
        "from datasets import load_dataset\n",
        "import torch, re"
      ],
      "metadata": {
        "id": "wychYj5yhlR8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
        "model = RobertaForQuestionAnswering.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "fcKGyO52h1Cg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804b9db7-8677-47de-e723-df7993e57dd7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squad_dev = load_dataset(\"squad_v2\", split=\"train[90:100]\")\n",
        "# squad_dev = load_dataset(\"squad_v2\", split=\"train+validation\") # UNCOMMENT THIS WHEN YOU KNOW RESULTS CAN PRINT\n",
        "squad_metric = load(\"squad_v2\")"
      ],
      "metadata": {
        "id": "Nn33cIL6iLv5"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "references = []\n",
        "\n",
        "for i in range(squad_dev.num_rows):\n",
        "  id = squad_dev[i]['id']\n",
        "  question = squad_dev[i][\"question\"]\n",
        "  context = squad_dev[i][\"context\"]\n",
        "  actual_answers = squad_dev[i][\"answers\"]\n",
        "  if len(actual_answers) == 0:\n",
        "    actual_answers = \"\"\n",
        "\n",
        "  tokenized_example = tokenizer(question, context, return_tensors=\"pt\", truncation=\"only_second\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output = model(**tokenized_example)\n",
        "\n",
        "  start_logits = output.start_logits\n",
        "  end_logits = output.end_logits\n",
        "\n",
        "  start_index = torch.argmax(start_logits)\n",
        "  end_index = torch.argmax(end_logits)\n",
        "\n",
        "  answer_tokens = tokenized_example['input_ids'][0][start_index:end_index + 1]\n",
        "  predicted_answer = tokenizer.decode(answer_tokens).strip()\n",
        "  # predicted_answer = re.sub(r'<s>|</s>', '', predicted_answer)\n",
        "  no_answer_probability = 0\n",
        "  if predicted_answer == \"<s>\":\n",
        "    predicted_answer = \"\"\n",
        "    no_answer_probability = 1\n",
        "\n",
        "  predictions.append({'id': id, 'prediction_text': predicted_answer, 'no_answer_probability': no_answer_probability})\n",
        "  references.append({'id': id, 'answers': actual_answers})\n",
        "\n",
        "  # print(f\"Question: {question}\")\n",
        "  # print(f\"Actual Answer: {actual_answers}\")\n",
        "  # print(f\"Predicted Answer: {predicted_answer}\")\n",
        "  # print()"
      ],
      "metadata": {
        "id": "h1Q0XVjp5fFQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0739f7a3-5b3a-4e14-8bb2-1e592c01c02d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What event occured after she was publicly criticized?\n",
            "Actual Answer: {'text': ['boyfriend left her'], 'answer_start': [320]}\n",
            "Predicted Answer: Her long-standing boyfriend left her\n",
            "\n",
            "Question: Who supported Beyonce through her depression?\n",
            "Actual Answer: {'text': ['her mother'], 'answer_start': [714]}\n",
            "Predicted Answer: her mother\n",
            "\n",
            "Question: What event caused Beyonce's depression?\n",
            "Actual Answer: {'text': ['split with Luckett and Rober'], 'answer_start': [194]}\n",
            "Predicted Answer: split\n",
            "\n",
            "Question: How long was Beyonce depressed?\n",
            "Actual Answer: {'text': ['a couple of years'], 'answer_start': [396]}\n",
            "Predicted Answer: a couple of years\n",
            "\n",
            "Question: Who helped Beyonce fight her depression the most?\n",
            "Actual Answer: {'text': ['her mother'], 'answer_start': [714]}\n",
            "Predicted Answer: her mother\n",
            "\n",
            "Question: Who replaced Luckett and Roberson in Destiny's Child?\n",
            "Actual Answer: {'text': ['Farrah Franklin and Michelle Williams.'], 'answer_start': [110]}\n",
            "Predicted Answer: Farrah Franklin and Michelle Williams\n",
            "\n",
            "Question: Who was blamed for Luckett and Roberson leaving Destiny's Child?\n",
            "Actual Answer: {'text': ['Beyoncé'], 'answer_start': [149]}\n",
            "Predicted Answer: Beyoncé\n",
            "\n",
            "Question: Who helped Beyoncé overcome her depression during the years following the Destiny's Child split?\n",
            "Actual Answer: {'text': ['her mother'], 'answer_start': [714]}\n",
            "Predicted Answer: her mother\n",
            "\n",
            "Question: Which newest member was removed from Destiny's Child?\n",
            "Actual Answer: {'text': ['Farrah Franklin'], 'answer_start': [110]}\n",
            "Predicted Answer: Farrah Franklin\n",
            "\n",
            "Question: \"Charlie's Angels\" featured which single from the band members?\n",
            "Actual Answer: {'text': ['Independent Women Part I'], 'answer_start': [37]}\n",
            "Predicted Answer: Independent Women Part I\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = squad_metric.compute(predictions=predictions, references=references)\n",
        "results"
      ],
      "metadata": {
        "id": "ToCnga3a70KI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a757506b-d34a-48c3-c664-ed2efa27e9c6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact': 80.0,\n",
              " 'f1': 90.83333333333334,\n",
              " 'total': 10,\n",
              " 'HasAns_exact': 80.0,\n",
              " 'HasAns_f1': 90.83333333333334,\n",
              " 'HasAns_total': 10,\n",
              " 'best_exact': 80.0,\n",
              " 'best_exact_thresh': 0.0,\n",
              " 'best_f1': 90.83333333333334,\n",
              " 'best_f1_thresh': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}